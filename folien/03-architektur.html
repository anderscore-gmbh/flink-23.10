<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="description" content="description"><meta name="author" content="Jan Lühr"><title>Apache Flink Worshop</title><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui" name="viewport"><link href="reveal.js-3.9.2/css/reveal.css" rel="stylesheet"><link href="reveal.js-3.9.2/plugin/title-footer/title-footer.css" rel="stylesheet"><link rel="stylesheet" href="reveal.js-3.9.2/css/theme/anderscore.css" id="theme"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css"><style>/* Stylesheet for CodeRay to match GitHub theme | MIT License | http://foundation.zurb.com */
pre.CodeRay{background:#f7f7f8}
.CodeRay .line-numbers{border-right:1px solid currentColor;opacity:.35;padding:0 .5em 0 0}
.CodeRay span.line-numbers{display:inline-block;margin-right:.75em}
.CodeRay .line-numbers strong{color:#000}
table.CodeRay{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.CodeRay td{vertical-align:top;line-height:inherit}
table.CodeRay td.line-numbers{text-align:right}
table.CodeRay td.code{padding:0 0 0 .75em}
.CodeRay .debug{color:#fff !important;background:#000080 !important}
.CodeRay .annotation{color:#007}
.CodeRay .attribute-name{color:#000080}
.CodeRay .attribute-value{color:#700}
.CodeRay .binary{color:#509}
.CodeRay .comment{color:#998;font-style:italic}
.CodeRay .char{color:#04d}
.CodeRay .char .content{color:#04d}
.CodeRay .char .delimiter{color:#039}
.CodeRay .class{color:#458;font-weight:bold}
.CodeRay .complex{color:#a08}
.CodeRay .constant,.CodeRay .predefined-constant{color:#008080}
.CodeRay .color{color:#099}
.CodeRay .class-variable{color:#369}
.CodeRay .decorator{color:#b0b}
.CodeRay .definition{color:#099}
.CodeRay .delimiter{color:#000}
.CodeRay .doc{color:#970}
.CodeRay .doctype{color:#34b}
.CodeRay .doc-string{color:#d42}
.CodeRay .escape{color:#666}
.CodeRay .entity{color:#800}
.CodeRay .error{color:#808}
.CodeRay .exception{color:inherit}
.CodeRay .filename{color:#099}
.CodeRay .function{color:#900;font-weight:bold}
.CodeRay .global-variable{color:#008080}
.CodeRay .hex{color:#058}
.CodeRay .integer,.CodeRay .float{color:#099}
.CodeRay .include{color:#555}
.CodeRay .inline{color:#000}
.CodeRay .inline .inline{background:#ccc}
.CodeRay .inline .inline .inline{background:#bbb}
.CodeRay .inline .inline-delimiter{color:#d14}
.CodeRay .inline-delimiter{color:#d14}
.CodeRay .important{color:#555;font-weight:bold}
.CodeRay .interpreted{color:#b2b}
.CodeRay .instance-variable{color:#008080}
.CodeRay .label{color:#970}
.CodeRay .local-variable{color:#963}
.CodeRay .octal{color:#40e}
.CodeRay .predefined{color:#369}
.CodeRay .preprocessor{color:#579}
.CodeRay .pseudo-class{color:#555}
.CodeRay .directive{font-weight:bold}
.CodeRay .type{font-weight:bold}
.CodeRay .predefined-type{color:inherit}
.CodeRay .reserved,.CodeRay .keyword {color:#000;font-weight:bold}
.CodeRay .key{color:#808}
.CodeRay .key .delimiter{color:#606}
.CodeRay .key .char{color:#80f}
.CodeRay .value{color:#088}
.CodeRay .regexp .delimiter{color:#808}
.CodeRay .regexp .content{color:#808}
.CodeRay .regexp .modifier{color:#808}
.CodeRay .regexp .char{color:#d14}
.CodeRay .regexp .function{color:#404;font-weight:bold}
.CodeRay .string{color:#d20}
.CodeRay .string .string .string{background:#ffd0d0}
.CodeRay .string .content{color:#d14}
.CodeRay .string .char{color:#d14}
.CodeRay .string .delimiter{color:#d14}
.CodeRay .shell{color:#d14}
.CodeRay .shell .delimiter{color:#d14}
.CodeRay .symbol{color:#990073}
.CodeRay .symbol .content{color:#a60}
.CodeRay .symbol .delimiter{color:#630}
.CodeRay .tag{color:#008080}
.CodeRay .tag-special{color:#d70}
.CodeRay .variable{color:#036}
.CodeRay .insert{background:#afa}
.CodeRay .delete{background:#faa}
.CodeRay .change{color:#aaf;background:#007}
.CodeRay .head{color:#f8f;background:#505}
.CodeRay .insert .insert{color:#080}
.CodeRay .delete .delete{color:#800}
.CodeRay .change .change{color:#66f}
.CodeRay .head .head{color:#f4f}</style><link href="reveal.js-3.9.2/lib/css/zenburn.css" rel="stylesheet"><script>document.write( '<link rel="stylesheet" href="reveal.js-3.9.2/css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );</script><script>document.write('<script src="http://' + (location.host || 'localhost').split(':')[0] + ':35729/livereload.js?snipver=1"></' + 'script>')</script></head><body><div class="reveal"><div class="slides"><section id="_die_architektur_von_apache_flink"><h2>Die Architektur von Apache Flink</h2><div class="paragraph heading center"><p>Die Architektur von Apache Flink</p></div></section>
<section id="_komponenten_eines_flink_clusters"><h2>Komponenten eines Flink-Clusters</h2><div class="ulist"><ul><li><p>Es gibt 2 Hauptkomponenten im Cluster: <strong>JobManager</strong> und <strong>TaskManager</strong></p></li><li><p>Nur 1 JobManager pro Cluster wird benötigt</p></li><li><p>Es kann beliebig viele TaskManager im Cluster geben</p></li><li><p>Ein JobManager hat folgende Komponenten:</p><div class="ulist"><ul><li><p>1 <strong>ResourceManager</strong></p></li><li><p>1 <strong>Dispatcher</strong></p></li><li><p>0 oder mehr <strong>JobMaster</strong></p></li></ul></div></li></ul></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="ulist"><ul><li><p><strong>JobMaster</strong></p><div class="ulist"><ul><li><p>Kontrolliert die Ausführung eines einzelnen Jobs</p></li><li><p>Jedem laufenden Job ist genau ein JobMaster zugeordnet</p></li></ul></div></li></ul></div></section>
<section id="_resourcemanager_und_dispatcher"><h2>ResourceManager und Dispatcher</h2><div class="ulist"><ul><li><p><strong>ResourceManager</strong></p><div class="ulist"><ul><li><p>Zuständig für (De-)Allokierung und Provisioning von Ressourcen für alle Jobs</p></li><li><p>Verwaltet TaskManagers, kann neue erstellen oder vorhandene beenden</p><div class="ulist"><ul><li><p>Für flexibles provisioning und recovery &#8594; availability</p></li><li><p>Dies ist nur in einem managed cluster möglich, nicht im standalone Cluster</p></li></ul></div></li><li><p>Unterschiedliche Implementierung je nach Umgebung: standalone, Kubernetes, YARN etc.</p></li></ul></div></li></ul></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="ulist"><ul><li><p><strong>Dispatcher</strong></p><div class="ulist"><ul><li><p>Nimmt Anfragen entgegen, neue Jobs zu starten</p></li><li><p>Ist über ein REST-Interface von außerhalb des Clusters aus ansprechbar</p></li><li><p>Verwaltet das Web-Interface (Dashboard)</p></li></ul></div></li></ul></div></section>
<section id="_taskmanager"><h2>TaskManager</h2><div class="ulist"><ul><li><p>Führt Tasks aus und leitet Daten (Streams) zwischen den Tasks weiter</p></li><li><p>Wird vom ResourceManager angesprochen, um für einen JobMaster Tasks auszuführen</p></li><li><p>Alle Tasks im TaskManager werden im selben JVM-Prozess ausgeführt</p></li><li><p>Hat eine begrenzte Anzahl von <strong>Task Slots</strong> (wird bei Erstellung des TaskManagers festgelegt)</p></li><li><p>Muss in standalone Clustern manuell erstellt werden</p></li></ul></div></section>
<section id="_komponenten_diagramm"><h2>Komponenten (Diagramm)</h2><div class="imageblock" style=""><img src="images/eigene/komponenten.png" alt="komponenten"></div></section>
<section id="_ausführen_eines_jobs_mit_mehreren_taskmanagern"><h2>Ausführen eines Jobs mit mehreren TaskManagern</h2><div class="imageblock" style=""><img src="images/eigene/job-execution/jobmehreretaskmanager.svg" alt="jobmehreretaskmanager" height="100%"></div></section>
<section id="_high_availability_mode"><h2>High-Availability Mode</h2><div class="ulist"><ul><li><p>Ein Flink-Cluster kann bei Bedarf im <strong>high-availability mode</strong> gestartet werden</p></li><li><p>Hauptidee: mehrere JobManager starten</p><div class="ulist"><ul><li><p>Es gibt dann einen Leader, der alleine alle Aufgaben erledigt</p></li><li><p>Der Rest ist in Standby</p></li><li><p>Bei Crash/Failure des Leaders wird ein neuer Leader unter den verbleibenden JobManagern gewählt</p></li></ul></div></li><li><p>Es muss dafür ein <strong>High-Availability-Service</strong> angegeben sein</p><div class="ulist"><ul><li><p><strong>Zookeeper Quorum</strong> ist eine mit Flink mitgelieferte Möglichkeit</p></li><li><p>Auch über den managed <strong>YARN Cluster</strong> oder <strong>Kubernetes Cluster</strong> möglich</p></li></ul></div></li><li><p><strong>Managed</strong> Cluster können auch TaskManager automatisch (neu-)starten</p></li></ul></div></section>
<section id="_task_slots"><h2>Task Slots</h2><div class="ulist"><ul><li><p>Unterteilungseinheit für die Ressourcen eines TaskManagers</p><div class="ulist"><ul><li><p>Jeder Slot in einem TaskManager erhält den gleichen Anteil von seinem Speicher</p></li><li><p>Es gibt keine CPU-Isolierung zwischen den Slots eines TaskManagers</p></li></ul></div></li><li><p>Jeder aktive Task wird genau einem Slot zugeordnet</p></li><li><p>Tasks im gleichen Slot sind nur schwach voneinander isoliert</p></li><li><p>Zur Isolierung der Tasks kann die Anzahl der Slots eines TaskManagers auf 1 gesetzt werden (Tradeoff mit Performance)</p></li></ul></div></section>
<section id="_slot_sharing"><h2>Slot Sharing</h2><div class="ulist"><ul><li><p>Konfigurierbar, aktiviert per default</p></li><li><p>Wenn deaktiviert, dann kann ein Slot nur einen Task gleichzeitig enthalten</p></li><li><p>Wenn aktiviert, dann können dem gleichen Slot mehrere Tasks zugeordnet werden (<strong>task group</strong>)</p><div class="ulist"><ul><li><p>Diese werden in einem Threadpool organisiert und können parallel ausgeführt werden</p></li></ul></div></li></ul></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="ulist"><ul><li><p>Regeln für die Zuordnung von Tasks zu Slots:</p><div class="ulist"><ul><li><p>Tasks im gleichen Slot müssen zum gleichen Job gehören</p></li><li><p>Ein Slot darf nicht verschiedene parallele Instanzen des gleichen Operators enthalten</p></li></ul></div></li><li><p>&#8594; Somit benötigt ein Job zur Ausführung mindestens so viele Task Slots wie der maximale Parallelismus seiner Operatoren ( = Parallelismus des Jobs )</p></li></ul></div></section>
<section id="_slot_sharing_2"><h2>Slot Sharing (2)</h2><div class="ulist"><ul><li><p>Wenn Slot Sharing aktiviert ist, dann ist in der Regel die Anzahl der Slots für einen Job sogar gleich seinem Parallelismus</p><div class="ulist"><ul><li><p>Die Slots enthalten dann jeweils einen kompletten parallelen Slice des Jobs</p></li><li><p>Somit leben Instanzen einer einzelnen parallelen Pipeline des Jobs immer auf der gleichen Node</p><div class="ulist"><ul><li><p>&#8594; Es müssen weniger Daten über das Netzwerk übertragen werden</p></li></ul></div></li></ul></div></li><li><p>Ohne Slot Sharing gibt es den Nachteil, dass alle Tasks die gleiche Menge an Ressourcen erhalten, auch wenn sie unterschiedlich viel benötigen</p><div class="ulist"><ul><li><p>Somit erhalten ressourcenintensive Tasks weniger Ressourcen</p></li></ul></div></li><li><p>Ohne Slot Sharing sind Tasks voneinander stärker isoliert</p><div class="ulist"><ul><li><p>Nur 1 Slot pro TaskManager ohne Slot Sharing garantiert nur 1 Task pro TaskManager</p></li></ul></div></li></ul></div></section>
<section id="_ausführen_einer_flinkanwendung"><h2>Ausführen einer Flinkanwendung</h2><div class="ulist"><ul><li><p>Flinkanwendungen können während ihrer Ausführung einen oder mehrere Jobs zur Ausführung an einen Flink-Cluster übergeben</p></li><li><p>Vor Ausführung des Jobs ordnet der JobMaster dem JobGraph einen ExecutionGraph zu</p></li><li><p>Die Tasks im ExecutionGraph können dann geeignet auf verfügbare Task Slots verteilt werden</p></li><li><p>Wenn nicht genügend Slots zur Verfügung stehen, dann schlägt die Ausführung des Jobs fehl</p><div class="ulist"><ul><li><p>Je nach Konfiguration kann der ResourceManager auch automatisch neue Slots provisionieren, indem neue TaskManager gestartet werden</p></li></ul></div></li></ul></div></section>
<section id="_beispiel_ausführen_eines_jobs_jobgraph_und_executiongraph"><h2>Beispiel Ausführen eines Jobs : JobGraph und ExecutionGraph</h2><table class="tableblock frame-all grid-all" style="width:100%"><colgroup><col style="width:28.5714%"><col style="width:71.4286%"></colgroup><tbody><tr><td class="tableblock halign-left valign-top"><div><div class="paragraph"><p><strong>Beispiel Job:</strong></p></div>
<div class="ulist"><ul><li><p>2 Quellen <strong>Q1</strong> und <strong>Q2</strong></p></li><li><p>Ein Operator <strong>Op</strong></p></li><li><p>Eine Senke <strong>S</strong></p></li></ul></div></div></td><td class="tableblock halign-left valign-top"><div><div class="imageblock" style=""><img src="images/eigene/job-execution/jobGraphExecutionGraph.png" alt="jobGraphExecutionGraph"></div></div></td></tr></table></section>
<section id="_beispiel_ausführen_eines_jobs_zuordnung_auf_task_slots"><h2>Beispiel Ausführen eines Jobs : Zuordnung auf Task Slots</h2><div class="imageblock" style=""><img src="images/eigene/job-execution/jobtaskmananager.svg" alt="jobtaskmananager" height="1100"></div></section>
<section id="_deployment_modes"><h2>Deployment Modes</h2><div class="ulist"><ul><li><p>Es gibt 2 mögliche <strong>Deployment Modes</strong> für Flink-Jobs:</p><div class="ulist"><ul><li><p><strong>Session Mode</strong></p><div class="ulist"><ul><li><p>Verwendet bereits existierenden Cluster zur Ausführung des Jobs</p></li><li><p>Anwendung wird im Client ausgeführt, um einen JobGraph zu erstellen, der dann an den Flink-Cluster geschickt wird</p></li><li><p>Ggf. werden vorher noch Dependencies im Client heruntergeladen</p></li></ul></div></li><li><p><strong>Application Mode</strong></p><div class="ulist"><ul><li><p>Erstellt für jede Anwendung einen neuen Flink Cluster</p></li><li><p>Anwendung wird vom JobManager serverseitig ausgeführt</p></li><li><p>Dependencies der Anwendung sind Teil des Clusters und müssen bei Neustart der Jobs nicht neu verteilt werden</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_datentransfer_zwischen_subtasks"><h2>Datentransfer zwischen Subtasks</h2><div class="ulist"><ul><li><p>Gegeben ein Subtask <em>A</em> eines Jobs, der seinen Output an einen Subtask <em>B</em> weiterleitet</p><div class="ulist"><ul><li><p>Dann hat <em>A</em> für diesen Kanal eine <strong>Output Buffer Queue</strong> und <em>B</em> eine <strong>Input Buffer Queue</strong></p></li><li><p>Wenn <em>A</em> und <em>B</em> vom gleichen TaskManager verwaltet werden, dann liegen die Buffer im gemeinsam genutzten Speicher</p><div class="ulist"><ul><li><p>Andernfalls werden vom TaskManager verwaltete Netzwerkbuffer verwendet</p></li></ul></div></li><li><p>Je 2 TaskManager erhalten eine ständige TCP-Verbindung, jede Remoteverbindung zwischen ihren <strong>Tasks</strong> erhält einen TCP-Kanal</p><div class="ulist"><ul><li><p>Daten von allen <strong>Subtasks</strong> von 2 Tasks werden unter Verwendung von Multiplexing über den gleichen TCP-Kanal übertragen</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_datentransfer_zwischen_subtasks_grafik"><h2>Datentransfer zwischen Subtasks (Grafik)</h2><div class="imageblock" style=""><img src="images/flink-network-stack2.png" alt="flink network stack2" width="1300" height="600"></div>
<div class="paragraph small center"><small><em>(Bildquelle: <a href="https://flink.apache.org/2019/06/05/a-deep-dive-into-flinks-network-stack/" class="bare">https://flink.apache.org/2019/06/05/a-deep-dive-into-flinks-network-stack/</a>)</em></small></div></section>
<section id="_deployment_von_subtasks"><h2>Deployment von Subtasks</h2><div class="ulist"><ul><li><p>Die möglichen <strong>Lokalisierungen</strong> von verbundenen <strong>Subtasks</strong> eines Jobs in abnehmender Verbindungsgeschwindigkeit:</p><div class="ulist"><ul><li><p>Im <strong>gleichen Task</strong> (verkettet)</p></li><li><p>In unterschiedlichen Tasks im <strong>gleichen TaskManager</strong></p></li><li><p>In unterschiedlichen TaskManagern auf der <strong>gleichen Node</strong></p></li><li><p>Auf <strong>unterschiedlichen Nodes</strong></p></li></ul></div></li><li><p>Abgesehen von der Verkettung, sind die anderen Möglichkeiten nicht direkt vom Entwickler einer Flink-Anwendung kontrollierbar</p><div class="ulist"><ul><li><p>Die Zuordnung von Tasks auf TaskManager wird automatisch vom <strong>Scheduler</strong> des Flink-Clusters vorgenommen</p></li></ul></div></li></ul></div></section>
<section id="_datentransfer_credit_based_flow_control"><h2>Datentransfer: Credit-Based Flow Control</h2><div class="ulist"><ul><li><p>Jeder Subtask verwaltet einen <strong>Pool</strong> von <strong>Floating Buffers</strong></p></li><li><p>Zusätzlich hat jede Input Buffer Queue dieses Subtasks auch noch <strong>exklusive Buffer</strong></p></li><li><p>Die Floating Buffers können bei Bedarf in exklusive Buffer umgewandelt werden</p></li></ul></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="ulist"><ul><li><p>Jeder Kanal zwischen 2 Subtasks hat eine Anzahl von <strong>Credits</strong></p><div class="ulist"><ul><li><p>entspricht der Anzahl der verfügbaren exklusiven Buffer der Queue des Empfängers</p></li></ul></div></li></ul></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="ulist"><ul><li><p><strong>Ziel</strong>: Jeder Kanal soll nicht mehr oder weniger exklusive Buffer haben, als er momentan benötigt</p><div class="ulist"><ul><li><p>&#8594; die vorhandenen Ressourcen werden optimal genutzt</p></li></ul></div></li></ul></div></section>
<section id="_datentransfer_credit_based_flow_control_2"><h2>Datentransfer: Credit-Based Flow Control (2)</h2><div class="imageblock" style=""><img src="images/flink-network-stack4.png" alt="flink network stack4" height="420"></div>
<div class="paragraph center small"><small><em>(Bildquelle: <a href="https://flink.apache.org/2019/06/05/a-deep-dive-into-flinks-network-stack/" class="bare">https://flink.apache.org/2019/06/05/a-deep-dive-into-flinks-network-stack/</a>)</em></small></div>
<div class="ulist"><ul><li><p>Credit-Based Flow Control:</p><div class="ulist"><ul><li><p>Buffer werden nur verschickt, wenn der Kanal genug Credits aufweist</p></li><li><p>Ankommende Buffer reduzieren die Anzahl der Credits</p></li><li><p>Sender schicken Empfängern mit den Buffern auch die Anzahl der noch wartenden Buffer (Größe ihres <strong>Backlogs</strong>)</p></li><li><p>Nach Erhalt der Buffer fragt der Empfänger ggf. weitere Buffer aus dem Pool an, um die Credits an die Größe des Backlogs anzugleichen</p></li></ul></div></li></ul></div></section>
<section id="_event_time_verarbeitung_watermark_propagation"><h2>Event-Time Verarbeitung : Watermark Propagation</h2><div class="ulist"><ul><li><p>Operatoren geben Watermarks von ihren Inputs an ihre Outputs weiter (<strong>propagation</strong>)</p></li><li><p>Ein Operator kann erst dann keine Ereignisse mit früherer <strong>event time</strong> als eine gegebene mehr erwarten, wenn dies für <strong>alle seine Inputs</strong> der Fall ist</p></li><li><p>Mechanismus für <strong>watermark propagation</strong>:</p><div class="ulist"><ul><li><p>Jeder Operator speichert für jeden seiner Inputs einen Timestamp</p><div class="ulist"><ul><li><p>Entspricht der <strong>letzten Watermark</strong>, die auf diesem Input angekommen ist</p></li></ul></div></li><li><p>Zusätzlich hat der Operator selbst auch noch einen Timestamp</p><div class="ulist"><ul><li><p>Entspricht dem <strong>Minimum</strong> der Timestamps seiner Inputs</p></li></ul></div></li><li><p>Immer wenn sich der Timestamp des Operators erhöht, emittiert dieser in seinen Outputs eine Watermark mit diesem Timestamp</p></li></ul></div></li></ul></div></section>
<section id="_event_time_verarbeitung_watermark_propagation_grafik"><h2>Event-Time Verarbeitung : Watermark Propagation (Grafik)</h2><div class="imageblock" style=""><img src="images/watermarks-propagation.jpg" alt="watermarks propagation" width="1300" height="600"></div>
<div class="paragraph small center"><small><em>(Bildquelle: "Stream Processing with Apache Flink" (F. Hueske, V. Kalavri), 1. Ed., 2019)</em></small></div></section>
<section id="_event_time_verarbeitung_watermark_propagation_mit_window_operators"><h2>Event-Time Verarbeitung : Watermark Propagation mit Window Operators</h2><div class="ulist"><ul><li><p>Sonderregeln für <strong>event-time Window Operators</strong>:</p><div class="ulist"><ul><li><p>Timestamp des Operators entscheidet, wann ein Window geschlossen wird</p></li><li><p>Watermarks werden nur bei Schließen des Windows zusammen mit dem Output emittiert</p></li></ul></div></li></ul></div></section>
<section id="_event_time_verarbeitung_idle_stream_problem"><h2>Event-Time Verarbeitung : Idle Stream Problem</h2><div class="ulist"><ul><li><p><strong>Idle stream problem</strong> bei Watermark Propagation:</p><div class="ulist"><ul><li><p>Wenn <strong>einer der Inputs</strong> eines Operators <strong>keine Aktivität</strong> hat:</p><div class="ulist"><ul><li><p>Dann wird der Timestamp dieses Inputs nicht mehr erhöht</p></li><li><p>Daher wird auch der Timestamp des Operators nicht erhöht</p></li><li><p>&#8594; Der Operator emittiert keine Watermarks mehr</p></li><li><p>&#8594; Window Operator schließt seine Windows nicht</p></li><li><p>&#8594; Pipeline ist lahmgelegt</p></li></ul></div></li></ul></div></li><li><p><strong>Lösungen</strong>:</p><div class="ulist"><ul><li><p>Partitionen besser <strong>balancieren</strong>, sodass keine leer oder dünn besetzt sind</p></li><li><p><strong>Keep-alive events</strong></p><div class="ulist"><ul><li><p>Auf jedem Input regelmäßig spezielle Ereignisse schicken</p></li></ul></div></li><li><p><strong>Idleness detection</strong></p><div class="ulist"><ul><li><p>Flink kann konfiguriert werden, Inaktivität eines Inputs zu erkennen und dieses nicht mehr für die Timestamps zu berücksichtigen</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_event_time_verarbeitung_watermark_alignment"><h2>Event-Time Verarbeitung : Watermark Alignment</h2><div class="ulist"><ul><li><p>Problemstellung:</p><div class="ulist"><ul><li><p><strong>event-time</strong> Window Operators, die einen <strong>Join</strong> von Inputs aus <strong>mehreren Quellen</strong> vornehmen, benötigen <strong>zeitlich auf einander abgestimmte</strong> Daten</p><div class="ulist"><ul><li><p>Beispiel : zeitlich korrelierte Messdaten, korreliertes Benutzerverhalten</p></li></ul></div></li><li><p>Wenn die Beschaffung oder Verarbeitung der Daten unterschiedlich lange dauert, können Daten mit ähnlicher <strong>event time</strong>, aber unterschiedlicher <strong>processing time</strong>
ankommen</p></li><li><p>&#8594; Windows verpassen Datensätze oder müssen sehr lange offen bleiben, um auf verspätete Datensätze zu warten</p></li></ul></div></li><li><p>Ansatz <strong>Watermark Alignment</strong>:</p><div class="ulist"><ul><li><p>Quellen können zu einer Gruppe gehören</p></li><li><p>Quellen in der gleichen Gruppe werden zeitlich aufeinander abgestimmt</p></li><li><p>"Schnellere" Quellen der Gruppe halten ggf. an, um auf "langsamere" zu warten</p></li></ul></div></li></ul></div></section>
<section id="_event_time_verarbeitung_watermark_alignment_2"><h2>Event-Time Verarbeitung : Watermark Alignment (2)</h2><div class="imageblock" style=""><img src="images/eigene/watermark-alignment.png" alt="watermark alignment" height="720"></div>
<div class="ulist"><ul><li><p>Jede Gruppe speichert den bisher <strong>maximalen</strong> Timestamp von <strong>Watermarks</strong> aus ihren Quellen</p></li><li><p>Quellen der Gruppe <strong>pausieren</strong>, solange der Timestamp ihres nächsten Datensatzes größer als die <strong>Summe</strong> aus Timestamp der Gruppe plus einem gegebenen <strong><em>Maximalen Drift</em></strong> ist</p></li></ul></div></section>
<section id="_event_time_verarbeitung_watermarkstrategy"><h2>Event-Time Verarbeitung : WatermarkStrategy</h2><div class="ulist"><ul><li><p>Watermarks werden in Flink über eine <strong>WatermarkStrategy</strong> konfiguriert</p><div class="ulist"><ul><li><p>Jeder Operator kann eine Strategy definieren, bevorzugt sollten dies aber nur die <strong>Quellen</strong> sein</p></li><li><p>Diese besteht aus einem <strong>TimestampAssigner</strong> und einem <strong>WatermarkGenerator</strong></p><div class="ulist"><ul><li><p>TimestampAssigner ist optional, um Datensätzen Timestamps (neu) zuzuordnen</p></li></ul></div></li></ul></div></li><li><p>Timestamps sind in Flink Long-Zahlenwerte in Millisekunden-Genauigkeit</p></li><li><p>Am Anfang jedes Streams mit Watermarks kommt ein Watermark mit Timestamp <em>Long.MIN_VALUE</em></p></li></ul></div></section>
<section id="_event_time_verarbeitung_watermarkgenerator"><h2>Event-Time Verarbeitung : WatermarkGenerator</h2><div class="ulist"><ul><li><p><strong>Patterns</strong> für WatermarkGenerators:</p><div class="ulist"><ul><li><p>Ein <strong>Periodic WatermarkGenerator</strong> erstellt in gleichmäßigen zeitlichen Abständen Watermarks</p><div class="ulist"><ul><li><p>die im Watermark verwendete Zeit kann z.B. auf dem zuletzt verarbeiteten Datensatz oder auf der aktuellen Systemzeit (processing time) basieren</p></li></ul></div></li><li><p>Ein <strong>Punctuated WatermarkGenerator</strong> erstellt ein Watermark immer dann, wenn ein Datensatz verarbeitet wurde, der ein bestimmtes Kriterium erfüllt</p><div class="ulist"><ul><li><p>erfordert, dass der Inputstream entsprechend markierte Datensätze enthält</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_zustandshaltung_in_flink"><h2>Zustandshaltung in Flink</h2><div class="ulist"><ul><li><p>In Flink wird der State getrennt für jeden Operator verwaltet, um erhöhte Performance und Isolation zu gewährleisten</p></li><li><p>Jeglicher State eines Jobs ist assoziiert mit einem seiner Operatoren</p></li><li><p>Der State eines Jobs entspricht der Menge der States aller Operatoren</p></li><li><p>In Flink wird der State eines Jobs als Einheit betrachtet, der nur insgesamt gespeichert oder geladen werden kann.</p><div class="ulist"><ul><li><p>Damit kann erreicht werden, dass die States aller Operatoren aufeinander abgestimmt (konsistent) bleiben</p></li></ul></div></li></ul></div></section>
<section id="_state_scopes"><h2>State Scopes</h2><div class="ulist"><ul><li><p>Es gibt 2 mögliche <strong>Scopes</strong> für State:</p><div class="ulist"><ul><li><p><strong>Operator State</strong> gehört zu einer parallelen <strong>Instanz</strong> des Operators (Subtask)</p></li><li><p><strong>Keyed State</strong> gehört zu einem <strong>Key</strong> des Inputstreams des Operators</p><div class="ulist"><ul><li><p>entspricht insgesamt einer Key-Value Map für diesen Operator</p></li></ul></div></li></ul></div></li></ul></div>
<table class="tableblock frame-none grid-none" style="width:100%"><colgroup><col style="width:50%"><col style="width:50%"></colgroup><tbody><tr><td class="tableblock halign-left valign-top"><div><div class="imageblock" style=""><img src="images/operator-state.jpg" alt="operator state" height="550"></div></div></td><td class="tableblock halign-left valign-top"><div><div class="imageblock" style=""><img src="images/keyed-state.jpg" alt="keyed state" height="550"></div></div></td></tr></table></section>
<section id="_raw_state_und_managed_state"><h2>Raw State und Managed State</h2><div class="ulist"><ul><li><p>State kann physisch in 2 Formen existieren (konfigurierbar) :</p><div class="ulist"><ul><li><p><strong>Raw State</strong> wird nur von den Tasks in ihren eigenen Datenstrukturen erhalten</p><div class="ulist"><ul><li><p>beschränkte Recovery- und Scaling-Funktionen</p></li></ul></div></li><li><p><strong>Managed State</strong> (default) wird von der Flinklaufzeit verwaltet von einem TaskManager in speziellen Datenstrukturen gespeichert</p><div class="ulist"><ul><li><p>empfohlen, da es Flink mehr Optimierungs- und Recoveryoptionen gibt</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_state_backends"><h2>State Backends</h2><div class="ulist"><ul><li><p>Für die Speicherung von Managed State muss ein <strong>State Backend</strong> gewählt werden</p></li><li><p>Dies kann global für den Cluster oder individuell für einen Job konfiguriert werden</p></li><li><p>Per Default unterstützt Flink 2 Arten von Backends:</p><div class="ulist"><ul><li><p><strong>HashMapStateBackend</strong></p></li><li><p><strong>EmbeddedRocksDBStateBackend</strong></p></li></ul></div></li></ul></div></section>
<section id="_state_backends_2"><h2>State Backends (2)</h2><div class="ulist"><ul><li><p><strong>HashMapStateBackend</strong></p><div class="ulist"><ul><li><p>Speichert State als Objekte im Java Heap (also im Arbeitsspeicher) des TaskManagers</p></li><li><p>Hohe Performance</p></li><li><p>Speicherplatz ist für die meisten Anwendungen ausreichend</p></li></ul></div></li></ul></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="ulist"><ul><li><p><strong>EmbeddedRocksDBStateBackend</strong></p><div class="ulist"><ul><li><p>Speichert State serialisiert in einer RocksDB Datenbank in einem lokalen Verzeichnis im permanenten Speicher des TaskManagers</p></li><li><p>Etwas geringere Performance</p></li><li><p>Für sehr großen State geeignet</p></li><li><p>Geeignet für high availability, da inkrementelle Snapshots unterstützt werden</p></li></ul></div></li></ul></div></section>
<section id="_state_typen"><h2>State Typen</h2><div class="ulist"><ul><li><p>Je nach Scope (Operator, Keyed) eines States sind unterschiedliche Typen auswählbar</p></li></ul></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="ulist"><ul><li><p>Für Keyed State und Operator State:</p><div class="ulist"><ul><li><p><strong>List State</strong> : Liste von Werten des gleichen Typs</p></li></ul></div></li></ul></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="ulist"><ul><li><p>Nur für Keyed State:</p><div class="ulist"><ul><li><p><strong>Value State</strong> : einzelner Wert</p></li><li><p><strong>Map State</strong> : Key-Value Map von Werten</p></li><li><p><strong>AggregatingState</strong> und <strong>ReducingState</strong> :</p><div class="ulist"><ul><li><p>Einzelner Wert</p></li><li><p>Hinzufügen von Datensätzen aktualisiert den State (Beispiel: Bilden einer Summe)</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_state_patterns"><h2>State Patterns</h2><div class="ulist"><ul><li><p>Zusätzlich werden folgende <strong>State Patterns</strong> von Flink unterstützt:</p><div class="ulist"><ul><li><p><strong>Broadcast State</strong> :</p><div class="ulist"><ul><li><p>Alle Operatorinstanzen teilen sich den State (Keyed oder Operator Scope)</p></li><li><p>Ein Upstream Operator broadcasted den State an alle Instanzen seiner Downstream Operatoren</p></li><li><p>Es gibt keine Kommunikation zwischen den Tasks zum Abgleich des Broadcast States</p></li><li><p>Nur für In-Memory State Backend verfügbar</p></li></ul></div></li><li><p><strong>Union List State</strong> :</p><div class="ulist"><ul><li><p>Wie List State, aber anderes Verhalten bei Scaling und Recovery (s.u.)</p></li><li><p>Sollte nicht für große States verwendet werden</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_stateverteilung_nach_operator_scaling"><h2>Stateverteilung nach Operator Scaling</h2><div class="ulist"><ul><li><p><strong>Operator Rescaling</strong> : Veränderung der Parallelität eines Operators</p><div class="ulist"><ul><li><p>Für stateful Operatoren muss der State umverteilt werden</p></li><li><p>Wird in Flink von Savepoints unterstüzt</p><div class="ulist"><ul><li><p>Zum Rescaling wird ein Savepoint erstellt und der Job einfach vom Savepoint aus mit veränderter Parallelität neu gestartet</p></li></ul></div></li></ul></div></li></ul></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="ulist"><ul><li><p>Wie wird der State nach Rescaling auf die neuen Operatorinstanzen verteilt?</p><div class="ulist"><ul><li><p>Bei <strong>Keyed State</strong>:</p><div class="ulist"><ul><li><p>Die möglichen Keys werden auf die neuen Instanzen verteilt und der State jedes Keys kann der zugehörigen Instanz zugeordnet werden</p></li><li><p>Für verbesserte Effizienz fasst Flink die Keys zu <strong>Key Groups</strong> zusammen und verteilt eigentlich diese</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_stateverteilung_nach_operator_scaling_keyed_grafik"><h2>Stateverteilung nach Operator Scaling : Keyed (Grafik)</h2><div class="imageblock" style=""><img src="images/opscaling-keyed.jpg" alt="opscaling keyed" width="1300" height="600"></div>
<div class="paragraph small center"><small><em>(Bildquelle: "Stream Processing with Apache Flink" (F. Hueske, V. Kalavri), 1. Ed., 2019)</em></small></div></section>
<section id="_stateverteilung_nach_operator_scaling_2"><h2>Stateverteilung nach Operator Scaling (2)</h2><div class="ulist"><ul><li><p>Wie wird der State nach Rescaling auf die neuen Operatorinstanzen verteilt?</p><div class="ulist"><ul><li><p>Bei <strong>Operator List State</strong>:</p><div class="ulist"><ul><li><p>Die Einträge der Listen aller ehemaligen Instanzen werden gleichmäßig auf die neuen Instanzen verteilt</p></li><li><p>Dies impliziert, dass die Listeneinträge voneinander unabhängig und die Operatorinstanzen in ihrer Funktion nicht unterscheidbar sind</p></li></ul></div></li><li><p>Bei <strong>Operator Union List State</strong>:</p><div class="ulist"><ul><li><p><strong>Jede</strong> Operatorinstanz erhält zunächst <strong>alle</strong> gespeicherten Listen</p></li><li><p>Daraufhin entscheidet jede Instanz, welche <strong>Teilmenge</strong> der Einträge sie behalten will</p></li><li><p>Hierfür sollten die Instanzen unterscheidbar sein bzw. verschiedene Rollen haben (z.B. individuelle Partitionierung)</p></li></ul></div></li><li><p>Bei <strong>Operator Broadcast State</strong>:</p><div class="ulist"><ul><li><p>Alle neuen Instanzen erhalten den (gleichen) State der alten Instanzen</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_stateverteilung_nach_operator_scaling_list_grafik"><h2>Stateverteilung nach Operator Scaling : List (Grafik)</h2><div class="imageblock" style=""><img src="images/opscaling-list.jpg" alt="opscaling list" width="1300" height="400"></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="paragraph small center"><small><em>(Bildquelle: "Stream Processing with Apache Flink" (F. Hueske, V. Kalavri), 1. Ed., 2019)</em></small></div></section>
<section id="_stateverteilung_nach_operator_scaling_union_grafik"><h2>Stateverteilung nach Operator Scaling : Union (Grafik)</h2><div class="imageblock" style=""><img src="images/opscaling-union.jpg" alt="opscaling union" width="1300" height="400"></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="paragraph small center"><small><em>(Bildquelle: "Stream Processing with Apache Flink" (F. Hueske, V. Kalavri), 1. Ed., 2019)</em></small></div></section>
<section id="_stateverteilung_nach_operator_scaling_broadcast_grafik"><h2>Stateverteilung nach Operator Scaling : Broadcast (Grafik)</h2><div class="imageblock" style=""><img src="images/opscaling-broadcast.jpg" alt="opscaling broadcast" width="1300" height="400"></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="paragraph"><p><em>(Bildquelle: "Stream Processing with Apache Flink" (F. Hueske, V. Kalavri), 1. Ed., 2019)</em></p></div></section>
<section id="_checkpoints_und_savepoints"><h2>Checkpoints und Savepoints</h2><div class="ulist"><ul><li><p><strong>Checkpoints</strong></p><div class="ulist"><ul><li><p>Flink kann in regelmäßigen Abständen den State eines Jobs in sog. Checkpoints persistieren</p></li><li><p>Es wird (per default) nur der eigentliche State der Operatoren, nicht der Inhalt von Buffern gespeichert</p></li><li><p>Dies sind (per default) in sich konsistente Abbilder des Zustands aller Operatoren im Job (<strong>self-consistent snapshot</strong>)</p></li></ul></div></li><li><p><strong>Recovery</strong></p><div class="ulist"><ul><li><p>im Fehlerfall wird der Job automatisch mit dem im letzten Checkpoint gespeicherten State neu gestartet</p></li></ul></div></li><li><p><strong>Savepoints</strong></p><div class="ulist"><ul><li><p>ein anderes Beispiel von self-consistent snapshots</p></li><li><p>werden nur auf manuellen Befehl hin angelegt oder geladen</p></li></ul></div></li></ul></div></section>
<section id="_self_consistent_snapshot"><h2>Self-consistent Snapshot</h2><div class="ulist"><ul><li><p>Ein <strong>snapshot</strong> (Momentaufnahme) des States eines Jobs ist <strong>self-consistent</strong>, wenn folgende Bedingung erfüllt ist:</p><div class="ulist"><ul><li><p>Es gibt einen <strong>Offset</strong> des Inputstreams, sodass gilt:</p><div class="ulist"><ul><li><p>Jeder Operator hat alle Datensätze im Inputstream, und daraus generierte Datensätze, bis zu diesem Offset vollständig bearbeitetet</p></li><li><p>Kein Operator hat einen Datensatz des Inputstreams mit einem größeren Offset bearbeitet</p></li></ul></div></li><li><p>Der Offset wird ebenfalls mit dem Snapshot gespeichert</p></li></ul></div></li></ul></div></section>
<section id="_interne_und_end_to_end_konsistenz"><h2>Interne und End-To-End-Konsistenz</h2><div class="ulist"><ul><li><p><strong>Interne Konsistenz</strong>:</p><div class="ulist"><ul><li><p>Wie oft durchläuft jeder Inputdatensatz (und daraus generierte Datensätze) physisch den Jobgraphen?</p><div class="ulist"><ul><li><p>Hierfür kann Flink starke Garantien bieten</p></li></ul></div></li></ul></div></li><li><p><strong>End-To-End Konsistenz</strong>:</p><div class="ulist"><ul><li><p>Wie oft werden die aus einem Inputdatensatz generierten Ergebnisse von den <strong>externen</strong> Senken tatsächlich verarbeitet?</p><div class="ulist"><ul><li><p>Hierfür kann Flink nur starke Garantien bieten, falls das externe System kompatibel ist</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_interne_konsistenz_in_flink"><h2>Interne Konsistenz in Flink</h2><div class="ulist"><ul><li><p>Nach <strong>Laden</strong> eines Flink-Jobs mit einem <strong>self-consistent snapshot</strong> seines States zum Offset <span class="blue-font"><strong>n</strong></span>:</p><div class="ulist"><ul><li><p>die Verarbeitung beginnt bei einem Offset <span class="orange-font"><strong>m</strong></span> &gt; <span class="blue-font"><strong>n</strong></span></p></li><li><p>&#8594; Es gibt keine falschen Ergebnisse durch nur teilweise verarbeitete Daten</p></li><li><p>&#8594; Interne Konsistenz ist immer (mindestens) <strong>at-most-once</strong></p></li></ul></div></li></ul></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="ulist"><ul><li><p><strong>Ideale</strong> Wahl: <span class="orange-font"><strong>m</strong></span> = <span class="blue-font"><strong>n</strong></span>+1</p><div class="ulist"><ul><li><p>&#8594; Interne Konsistenz <strong>exactly once</strong></p></li><li><p>Erfordert Zurückrollbarkeit der Quelle</p></li></ul></div></li></ul></div></section>
<section id="_end_to_end_konsistenz_mit_flink"><h2>End-To-End Konsistenz mit Flink</h2><div class="ulist"><ul><li><p>Zurückrollbare Quellen (<strong>at-least-once</strong> Semantik):</p><div class="ulist"><ul><li><p>Beispiel : Datei (filepointer), Kafka Topic (partition offsets)</p></li><li><p>Gegenbeispiel : Netzwerksocket ohne Caching</p></li></ul></div></li></ul></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="ulist"><ul><li><p>Damit keine Ausgaben zweimal passieren (<strong>end-to-end at-most-once</strong>), muss auch der Outputstream der Senken effektiv zurückrollbar sein (schwierig)</p><div class="ulist"><ul><li><p>Beispiel : Kafka Topic (mit transaktionalen commits)</p></li><li><p>Gegenbeispiel : jeder externe Konsument ohne spezielle dahingehende Funktionalität</p></li></ul></div></li></ul></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="ulist"><ul><li><p>&#8594; Wenn beides gegeben ist, kann also mit Flink sogar <strong>end-to-end exactly-once</strong> garantiert werden</p></li></ul></div></section>
<section id="_checkpointing_algorithmus"><h2>Checkpointing Algorithmus</h2><div class="ulist"><ul><li><p>Um einen Checkpoint zu erstellen, sollte nicht der gesamte Job angehalten werden müssen</p></li><li><p>Für einen Checkpoint werden an den Quellen spezielle Datensätze namens <strong>Barriers</strong> hinzugefügt,
die ähnlich wie Watermarks keine Daten, sondern nur die <strong>ID des Checkpoints</strong> enthalten</p><div class="ulist"><ul><li><p>Diese zeigen an, dass <strong>alle späteren Datensätze nicht mehr zu diesem Checkpoint</strong> gehören</p></li></ul></div></li></ul></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="imageblock" style=""><img src="images/stream_barriers.svg" alt="stream barriers" height="350px"></div>
<div class="paragraph small center"><small>(Bildquelle: <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/concepts/stateful-stream-processing/" class="bare">https://nightlies.apache.org/flink/flink-docs-master/docs/concepts/stateful-stream-processing/</a>)</small></div></section>
<section id="_checkpointing_algorithmus_2"><h2>Checkpointing Algorithmus (2)</h2><div class="ulist"><ul><li><p>Es gibt für jeden Job einen <strong>Checkpoint Coordinator</strong> als Teil des JobManagers</p></li><li><p>Checkpointing Algorithmus:</p><div class="ulist"><ul><li><p>Barriers werden an den <strong>Quellen</strong> hinzugefügt</p></li><li><p>Sobald ein <strong>Operator</strong> Barriers von allen seinen Inputs erhalten hat, persistiert er seinen State und emittiert Barriers in seinen Outputs</p></li><li><p>Sobald eine <strong>Senke</strong> Barriers von allen ihren Inputs erhalten hat, meldet sie dies an den Checkpoint Coordinator</p></li><li><p>Wenn das für alle Senken im Job passiert ist, beschließt der Checkpoint Coordinator den Checkpoint</p></li><li><p>&#8594; <strong>self-consistent snapshot</strong> zum letzten Offset vor der Barrier</p></li></ul></div></li></ul></div></section>
<section id="_checkpointing_algorithmus_aligned_checkpointing"><h2>Checkpointing Algorithmus : Aligned Checkpointing</h2><div class="ulist"><ul><li><p>Wenn ein Operator <strong>mehrere Inputs</strong> hat, dann muss er nach Erhalt einer Barrier auf einem Inputkanal die Verarbeitung auf diesem Kanal <strong>anhalten</strong>, bis er
auch auf allen anderen Inputs Barriers erhalten hat</p><div class="ulist"><ul><li><p>Da der gespeicherte State nur die Verarbeitung bis zu den Barriers repräsentieren soll</p></li><li><p>&#8594; Die Inputs sind dann aufeinander abgestimmt (<strong>aligned</strong>)</p></li></ul></div></li><li><p>Dies führt zu einem <strong>aligned checkpoint</strong> und ist das Defaultverhalten von Flink</p></li></ul></div></section>
<section id="_checkpoint_alghorithmus_aligned_checkpointing_grafik"><h2>Checkpoint Alghorithmus : Aligned Checkpointing (Grafik)</h2><div class="imageblock" style=""><img src="images/from-aligned-to-unaligned-checkpoints-part-1-3.png" alt="from aligned to unaligned checkpoints part 1 3" width="2000"></div>
<div class="paragraph small center"><small><em>(Bildquelle: <a href="https://flink.apache.org/2020/10/15/from-aligned-to-unaligned-checkpoints-part-1-checkpoints-alignment-and-backpressure/" class="bare">https://flink.apache.org/2020/10/15/from-aligned-to-unaligned-checkpoints-part-1-checkpoints-alignment-and-backpressure/</a>)</em></small></div></section>
<section id="_checkpointing_algorithmus_aligned_checkpointing_nachteile"><h2>Checkpointing Algorithmus : Aligned Checkpointing (Nachteile)</h2><div class="ulist"><ul><li><p>aligned checkpoints sind oft eine sinnvolle Wahl, aber nicht immer</p></li><li><p>Mögliche Nachteile :</p><div class="ulist"><ul><li><p>Blockieren der Operatoren lässt CPU-Ressourcen des Clusters ungenutzt und kann zu Latenzen führen</p></li><li><p>Erstellen eines Checkpoints <strong>kann</strong> sehr lange dauern</p><div class="ulist"><ul><li><p>&#8594; Seltenere Checkpoints</p></li></ul></div></li></ul></div></li></ul></div>
<div class="paragraph"><p>&#160;<br></p></div>
<div class="ulist"><ul><li><p>Eine Alternative sind <strong>unaligned checkpoints</strong></p></li></ul></div></section>
<section id="_checkpointing_algorithmus_unaligned_checkpointing"><h2>Checkpointing Algorithmus : Unaligned Checkpointing</h2><div class="ulist"><ul><li><p>Für <strong>unaligned checkpoints</strong> wird nicht nur der State des Operators, sondern auch die Daten in seinen <strong>Buffern</strong> gespeichert (<strong>in-flight data</strong>)</p></li><li><p>Unaligned Checkpointing Algorithmus:</p><div class="ulist"><ul><li><p>Wenn ein Operator <strong>das erste Mal</strong> auf einem seiner <strong>Inputbuffer</strong> eine <strong>Barrier</strong> erhält, dann:</p><div class="ulist"><ul><li><p>Fügt er sofort eine Barrier ans Ende seiner <strong>Outputbuffer</strong> an</p></li><li><p>Persistiert er seinen State</p></li><li><p>Markiert er alle hinter der neuen Barrier liegenden Buffer zur Persistierung</p></li></ul></div></li></ul></div></li><li><p>Konsistenzgarantien sind die gleichen wie für aligned checkpoints</p></li></ul></div></section>
<section id="_checkpointing_algorithmus_unaligned_checkpointing_grafik"><h2>Checkpointing Algorithmus : Unaligned Checkpointing (Grafik)</h2><div class="imageblock" style=""><img src="images/stream_unaligning.svg" alt="stream unaligning" width="2000"></div>
<div class="paragraph small center"><small><em>(Bildquelle: <a href="https://flink.apache.org/2020/10/15/from-aligned-to-unaligned-checkpoints-part-1-checkpoints-alignment-and-backpressure/" class="bare">https://flink.apache.org/2020/10/15/from-aligned-to-unaligned-checkpoints-part-1-checkpoints-alignment-and-backpressure/</a>)</em></small></div></section>
<section id="_checkpointing_algorithmus_aligned_vs_unaligned_checkpointing"><h2>Checkpointing Algorithmus : Aligned vs Unaligned Checkpointing</h2><div class="ulist"><ul><li><p><strong>Vorteile</strong> von <strong>unaligned checkpoints</strong>:</p><div class="ulist"><ul><li><p>Barriers erreichen Senken schneller</p><div class="ulist"><ul><li><p>&#8594; Häufigere Checkpoints möglich</p></li></ul></div></li><li><p>Zeit für Checkpointing ist von der End-To-End-Latenz des Jobs unabhängig</p></li></ul></div></li><li><p><strong>Einschränkungen</strong> von <strong>unaligned checkpoints</strong>:</p><div class="ulist"><ul><li><p>mehr IO nötig für Speichern der Buffer, größerer Speicherbedarf</p><div class="ulist"><ul><li><p>Checkpointing ist nur dann schneller, wenn IO kein Bottleneck ist</p></li></ul></div></li><li><p>Laden dauert länger und erfordert Wiederverarbeitung der gespeicherten Buffer</p></li><li><p>Laden von Watermarks ist leicht unterschiedlich</p><div class="ulist"><ul><li><p>für Details siehe <a href="https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/ops/state/checkpointing_under_backpressure/" class="bare">https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/ops/state/checkpointing_under_backpressure/</a></p></li></ul></div></li><li><p>es können nicht mehrere Checkpoints gleichzeitig erstellt werden</p></li></ul></div></li></ul></div></section>
<section id="_recovery_von_checkpoints_vorgang"><h2>Recovery von Checkpoints (Vorgang)</h2><div class="imageblock" style=""><img src="images/from-aligned-to-unaligned-checkpoints-part-1-4.png" alt="from aligned to unaligned checkpoints part 1 4" width="2000"></div>
<div class="paragraph small center"><small><em>(Bildquelle: <a href="https://flink.apache.org/2020/10/15/from-aligned-to-unaligned-checkpoints-part-1-checkpoints-alignment-and-backpressure/" class="bare">https://flink.apache.org/2020/10/15/from-aligned-to-unaligned-checkpoints-part-1-checkpoints-alignment-and-backpressure/</a>)</em></small></div>
<div class="ulist"><ul><li><p>Für unaligned Checkpointing kommt noch der Schritt hinzu, die gespeicherten Buffer zu laden</p></li></ul></div></section>
<section id="_incremental_checkpointing"><h2>Incremental Checkpointing</h2><div class="ulist"><ul><li><p>Idee von <strong>incremental checkpointing</strong>:</p><div class="ulist"><ul><li><p>Nur die Veränderungen im Vergleich zum letzten Checkpoint speichern</p></li></ul></div></li><li><p>Nicht alle State Backends unterstützen dieses Feature (per Default nur <strong>RockDB</strong>)</p></li><li><p>Vorteile:</p><div class="ulist"><ul><li><p>Weniger Speicherbedarf bei <strong>großem State</strong></p></li><li><p>Recovery kann schneller sein (weniger <strong>CPU</strong>- und <strong>IO</strong>-Ressourcen benötigt)</p></li></ul></div></li><li><p>Nachteile:</p><div class="ulist"><ul><li><p>Recovery kann auch länger dauern, da ggf. eine History von mehreren Checkpoints geladen werden muss (&#8594; <strong>Netzwerklast</strong>)</p><div class="ulist"><ul><li><p>RockDB verwendet <strong>Compaction</strong>, um inkrementelle Checkpoints zusammenzufassen und die Größe der History zu beschränken</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_weitere_optionen_für_checkpointing"><h2>Weitere Optionen für Checkpointing</h2><div class="ulist"><ul><li><p><strong>at-least-once Checkpointing</strong></p><div class="ulist"><ul><li><p>Entspricht unaligned checkpointing ohne Speicherung der Buffer</p><div class="ulist"><ul><li><p>&#8594; Schnell, aber keine at-most-once Konsistenz</p></li></ul></div></li><li><p>Interessant, falls sehr niedrige Latenzen wichtig sind</p></li></ul></div></li><li><p><strong>concurrent checkpointing</strong></p><div class="ulist"><ul><li><p>Es können mehrere Checkpoints gleichzeitig erstellt werden</p></li><li><p>Keine Probleme mit Konsistenz, allerdings kann es zu erhöhten Latenzen führen</p></li><li><p>Interessant, wenn <strong>aligned</strong> Checkpoints mit hoher Frequenz benötigt werden</p></li></ul></div></li><li><p><strong>externalized checkpoints</strong></p><div class="ulist"><ul><li><p>Checkpoints werden in externen Speicher persistiert</p></li><li><p>Ermöglicht es, Checkpoints zu erhalten, auch nachdem ein Job <strong>abgebrochen</strong> wurde</p></li><li><p>Jobs können dann manuell mit diesen Checkpointdaten neugestartet werden</p></li></ul></div></li></ul></div></section>
<section id="_savepoints"><h2>Savepoints</h2><div class="ulist"><ul><li><p>Savepoints haben die Funktion eines <strong>Backups</strong>, um die Konsistenz eines Jobs nach <strong>geplanten Downtimes</strong> (Updates, Rescaling, Migration &#8230;&#8203;) zu erhalten</p></li><li><p>Erstellen, Laden und Löschen muss manuell ausgelöst werden</p></li><li><p>Werden nach dem gleichen Algorithmus wie <strong>aligned</strong> Checkpoints erstellt</p></li><li><p>Enthalten zusätzliche <strong>Metainformationen</strong></p></li><li><p>Portabler und <strong>flexibler</strong> als Checkpoints, dafür langsamer zu laden</p><div class="ulist"><ul><li><p>Können mit veränderten Versionen des gleichen Jobs verwendet werden, solange die States kompatibel sind</p></li><li><p>Können nach Update von Flink oder Änderung des State Backends weiter verwendet werden</p></li></ul></div></li></ul></div></section></div></div><script src="reveal.js-3.9.2/lib/js/head.min.js"></script><script src="reveal.js-3.9.2/js/reveal.js"></script><script>// See https://github.com/hakimel/reveal.js#configuration for a full list of configuration options
Reveal.initialize({
  // Display controls in the bottom right corner
  controls: true,
  // Display a presentation progress bar
  progress: true,
  // Display the page number of the current slide
  slideNumber: true,
  // Push each slide change to the browser history
  history: true,
  // Enable keyboard shortcuts for navigation
  keyboard: true,
  // Enable the slide overview mode
  overview: true,
  // Vertical centering of slides
  center: true,
  // Enables touch navigation on devices with touch input
  touch: true,
  // Loop the presentation
  loop: false,
  // Change the presentation direction to be RTL
  rtl: false,
  // Turns fragments on and off globally
  fragments: true,
  // Flags if the presentation is running in an embedded mode,
  // i.e. contained within a limited portion of the screen
  embedded: false,
  // Number of milliseconds between automatically proceeding to the
  // next slide, disabled when set to 0, this value can be overwritten
  // by using a data-autoslide attribute on your slides
  autoSlide: 0,
  // Stop auto-sliding after user input
  autoSlideStoppable: true,
  // Enable slide navigation via mouse wheel
  mouseWheel: true,
  // Hides the address bar on mobile devices
  hideAddressBar: true,
  // Opens links in an iframe preview overlay
  previewLinks: false,
  // Theme (e.g., beige, black, league, night, serif, simple, sky, solarized, white)
  // NOTE setting the theme in the config no longer works in reveal.js 3.x
  //theme: Reveal.getQueryHash().theme || 'anderscore',
  // Transition style (e.g., none, fade, slide, convex, concave, zoom)
  transition: Reveal.getQueryHash().transition || 'linear',
  // Transition speed (e.g., default, fast, slow)
  transitionSpeed: 'default',
  // Transition style for full page slide backgrounds (e.g., none, fade, slide, convex, concave, zoom)
  backgroundTransition: 'fade',
  // Number of slides away from the current that are visible
  viewDistance: 3,
  // Parallax background image (e.g., "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'")
  parallaxBackgroundImage: '',
  // Parallax background size in CSS syntax (e.g., "2100px 900px")
  parallaxBackgroundSize: '',

  // The "normal" size of the presentation, aspect ratio will be preserved
  // when the presentation is scaled to fit different resolutions. Can be
  // specified using percentage units.
  width: 1728,
  height: 972,

  // Factor of the display size that should remain empty around the content
  margin: 0.1,

  // Bounds for smallest/largest possible scale to apply to content
  minScale: 0.2,
  maxScale: 1.5,

  // Optional libraries used to extend on reveal.js
  dependencies: [
      { src: 'reveal.js-3.9.2/lib/js/classList.js', condition: function() { return !document.body.classList; } },
      { src: 'reveal.js-3.9.2/plugin/title-footer/title-footer.js', async: true, callback: function()
          {title_footer.initialize('Schulung Java Data Pipelines mit Apache Flink', 'Jan Lühr', 'anderScore GmbH • Frankenwerft 35 • 50667 Köln');}},
      { src: 'reveal.js-3.9.2/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'reveal.js-3.9.2/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      
      { src: 'reveal.js-3.9.2/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
      { src: 'reveal.js-3.9.2/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
  ]
});</script></body></html>