<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="description" content="description"><meta name="author" content="Jan Lühr"><title>Apache Flink Worshop</title><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui" name="viewport"><link href="reveal.js-3.9.2/css/reveal.css" rel="stylesheet"><link href="reveal.js-3.9.2/plugin/title-footer/title-footer.css" rel="stylesheet"><link rel="stylesheet" href="reveal.js-3.9.2/css/theme/anderscore.css" id="theme"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css"><style>/* Stylesheet for CodeRay to match GitHub theme | MIT License | http://foundation.zurb.com */
pre.CodeRay{background:#f7f7f8}
.CodeRay .line-numbers{border-right:1px solid currentColor;opacity:.35;padding:0 .5em 0 0}
.CodeRay span.line-numbers{display:inline-block;margin-right:.75em}
.CodeRay .line-numbers strong{color:#000}
table.CodeRay{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.CodeRay td{vertical-align:top;line-height:inherit}
table.CodeRay td.line-numbers{text-align:right}
table.CodeRay td.code{padding:0 0 0 .75em}
.CodeRay .debug{color:#fff !important;background:#000080 !important}
.CodeRay .annotation{color:#007}
.CodeRay .attribute-name{color:#000080}
.CodeRay .attribute-value{color:#700}
.CodeRay .binary{color:#509}
.CodeRay .comment{color:#998;font-style:italic}
.CodeRay .char{color:#04d}
.CodeRay .char .content{color:#04d}
.CodeRay .char .delimiter{color:#039}
.CodeRay .class{color:#458;font-weight:bold}
.CodeRay .complex{color:#a08}
.CodeRay .constant,.CodeRay .predefined-constant{color:#008080}
.CodeRay .color{color:#099}
.CodeRay .class-variable{color:#369}
.CodeRay .decorator{color:#b0b}
.CodeRay .definition{color:#099}
.CodeRay .delimiter{color:#000}
.CodeRay .doc{color:#970}
.CodeRay .doctype{color:#34b}
.CodeRay .doc-string{color:#d42}
.CodeRay .escape{color:#666}
.CodeRay .entity{color:#800}
.CodeRay .error{color:#808}
.CodeRay .exception{color:inherit}
.CodeRay .filename{color:#099}
.CodeRay .function{color:#900;font-weight:bold}
.CodeRay .global-variable{color:#008080}
.CodeRay .hex{color:#058}
.CodeRay .integer,.CodeRay .float{color:#099}
.CodeRay .include{color:#555}
.CodeRay .inline{color:#000}
.CodeRay .inline .inline{background:#ccc}
.CodeRay .inline .inline .inline{background:#bbb}
.CodeRay .inline .inline-delimiter{color:#d14}
.CodeRay .inline-delimiter{color:#d14}
.CodeRay .important{color:#555;font-weight:bold}
.CodeRay .interpreted{color:#b2b}
.CodeRay .instance-variable{color:#008080}
.CodeRay .label{color:#970}
.CodeRay .local-variable{color:#963}
.CodeRay .octal{color:#40e}
.CodeRay .predefined{color:#369}
.CodeRay .preprocessor{color:#579}
.CodeRay .pseudo-class{color:#555}
.CodeRay .directive{font-weight:bold}
.CodeRay .type{font-weight:bold}
.CodeRay .predefined-type{color:inherit}
.CodeRay .reserved,.CodeRay .keyword {color:#000;font-weight:bold}
.CodeRay .key{color:#808}
.CodeRay .key .delimiter{color:#606}
.CodeRay .key .char{color:#80f}
.CodeRay .value{color:#088}
.CodeRay .regexp .delimiter{color:#808}
.CodeRay .regexp .content{color:#808}
.CodeRay .regexp .modifier{color:#808}
.CodeRay .regexp .char{color:#d14}
.CodeRay .regexp .function{color:#404;font-weight:bold}
.CodeRay .string{color:#d20}
.CodeRay .string .string .string{background:#ffd0d0}
.CodeRay .string .content{color:#d14}
.CodeRay .string .char{color:#d14}
.CodeRay .string .delimiter{color:#d14}
.CodeRay .shell{color:#d14}
.CodeRay .shell .delimiter{color:#d14}
.CodeRay .symbol{color:#990073}
.CodeRay .symbol .content{color:#a60}
.CodeRay .symbol .delimiter{color:#630}
.CodeRay .tag{color:#008080}
.CodeRay .tag-special{color:#d70}
.CodeRay .variable{color:#036}
.CodeRay .insert{background:#afa}
.CodeRay .delete{background:#faa}
.CodeRay .change{color:#aaf;background:#007}
.CodeRay .head{color:#f8f;background:#505}
.CodeRay .insert .insert{color:#080}
.CodeRay .delete .delete{color:#800}
.CodeRay .change .change{color:#66f}
.CodeRay .head .head{color:#f4f}</style><link href="reveal.js-3.9.2/lib/css/zenburn.css" rel="stylesheet"><script>document.write( '<link rel="stylesheet" href="reveal.js-3.9.2/css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );</script><script>document.write('<script src="http://' + (location.host || 'localhost').split(':')[0] + ':35729/livereload.js?snipver=1"></' + 'script>')</script></head><body><div class="reveal"><div class="slides"><section id="_betrieb"><h2>Betrieb</h2><div class="paragraph heading center"><p>Betrieb eines Flink-Clusters</p></div></section>
<section id="_cluster_setups"><h2>Cluster Setups</h2><div class="ulist"><ul><li><p>Mögliche Setups für einen Flinkcluster:</p><div class="ulist"><ul><li><p>Non managed:</p><div class="ulist"><ul><li><p>Standalone ohne Docker</p></li><li><p>Standalone mit Docker</p></li></ul></div></li><li><p>Managed:</p><div class="ulist"><ul><li><p>YARN (Hadoop Cluster)</p></li><li><p>Kubernetes (nativ/nicht-nativ)</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_setup_standalone_cluster_ohne_docker_skizze"><h2>Setup Standalone Cluster (ohne Docker), Skizze</h2><div class="ulist"><ul><li><p>Die Flink-Distribution muss sich auf allen Nodes im Cluster auf dem gleichen Pfad befinden</p></li><li><p>In der Konfiguration sollte Hostname und Port des JobManagers eingestellt sein (<em>jobmanager.rpc.address</em>, <em>jobmanager.rpc.port</em>)</p><div class="ulist"><ul><li><p>In High-Availability Setups wird statt dessen zuerst die Verbindung zu dem verwendeten High-Availability-Service (z.B. Zookeeper) hergestellt</p></li></ul></div></li><li><p>Auf der Node für den JobManager kann dann start-cluster.sh ausgeführt werden, und auf jeder Node manuell die gewünschte Anzahl von TaskManagers
gestartet werden</p></li><li><p>falls benötigt, kann noch die externe Rest-Schnittstelle konfiguriert werden</p></li></ul></div></section>
<section id="_setup_standalone_cluster_mit_docker_skizze"><h2>Setup Standalone Cluster (mit Docker), Skizze</h2><div class="ulist"><ul><li><p>Im Setup mit Docker läuft der JobManager und alle TaskManager je in einem Container</p><div class="ulist"><ul><li><p>Als Image kann "flink" (DockerHub) verwendet werden, z.B. flink:latest</p></li></ul></div></li><li><p>Die Konfiguration kann beim Start des Containers über die Umgebungsvariable FLINK_PROPERTIES mitgegeben werden</p></li><li><p>wie vorher sollte diese zumindest die Netzwerkadresse des JobManagers enthalten</p></li><li><p>Beispiel für Start eines JobManagers:</p></li></ul></div>
<pre class="CodeRay listingblock"><code class="script language-script">$ docker run \
    --rm \
    --name=jobmanager \
    --network flink-network \
    --publish 8081:8081 \
    --env FLINK_PROPERTIES=&quot;${FLINK_PROPERTIES}&quot; \
    flink:latest jobmanager</code></pre>
<div class="ulist"><ul><li><p>Komplette Anleitung : <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/resource-providers/standalone/docker/" class="bare">https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/resource-providers/standalone/docker/</a></p></li><li><p>Was sind Vorteile/Nachteile bei der Verwendung von Docker?</p></li></ul></div></section>
<section id="_setup_mit_kubernetes_skizze"><h2>Setup mit Kubernetes, Skizze</h2><div class="ulist"><ul><li><p>Ein Flink-Cluster kann auf einem Kubernetes-Cluster ("on top") deployed werden, indem manuell geeignete Deployment-Skripte für die
JobManager- und TaskManager-Services festgelegt werden (nicht-nativer Setup)</p></li><li><p>Auf der Seite <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/resource-providers/standalone/kubernetes/" class="bare">https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/resource-providers/standalone/kubernetes/</a> befinden
sich Beispielskripte dafür</p></li><li><p>Im nativen Setup wird der Flink-Cluster stärker mit dem Kubernetes-Cluster verzahnt, sodass Flink z.B. direkt TaskManagers allokieren und deallokieren kann (Stichwort "Flink Kubernetes Operator")</p></li><li><p>Anleitung zum Start im nativen Setup aus der Flink-Dokumentation:</p></li></ul></div>
<pre class="CodeRay listingblock"><code class="shell language-shell"># (1) Start Kubernetes session
$ ./bin/kubernetes-session.sh -Dkubernetes.cluster-id=my-first-flink-cluster

# (2) Submit example job
$ ./bin/flink run \
    --target kubernetes-session \
    -Dkubernetes.cluster-id=my-first-flink-cluster \
    ./examples/streaming/TopSpeedWindowing.jar

# (3) Stop Kubernetes session by deleting cluster deployment
$ kubectl delete deployment/my-first-flink-cluster</code></pre></section>
<section id="_konfigurationsparameter"><h2>Konfigurationsparameter</h2><div class="ulist"><ul><li><p>Clusterweite Werte für die Konfigurationsparameter können in <em>conf/flink-conf.yaml</em> im Flink-Verzeichnis festgelegt werden</p><div class="ulist"><ul><li><p>Das Verzeichnis lässt sich über die Umgebungsvariable FLINK_CONF_DIR anpassen</p></li></ul></div></li><li><p>Für die Ausführung eines Jobs spezifische Parameter können auch durch Methoden auf dem ExecutionEnvironment festgelegt werden:</p><div class="ulist"><ul><li><p>Runtime Mode (s.o.), Parallelismus, Max. Parallelismus (= Anzahl möglicher Key Groups), Restart-Strategie, State Backend, Buffer Timeout ..</p></li></ul></div></li></ul></div></section>
<section id="_logging"><h2>Logging</h2><div class="ulist"><ul><li><p>Es kann jedes Logging-Framework verwendet werden, das SLF4J unterstützt</p><div class="ulist"><ul><li><p>Default ist Log4J2</p><div class="ulist"><ul><li><p>Die Log4J2-Konfiguration der Anwendung beeinflusst dann das gesamte Logging für die Ausführung des Jobs</p></li></ul></div></li></ul></div></li><li><p>Die Logs werden in einem lokalen Verzeichnis gespeichert und können auch in der WebUI eingesehen werden</p></li><li><p>Best Practice: Nur Ausnahmen wie Fehler loggen</p></li></ul></div></section>
<section id="_restart_strategien_für_anwendungen"><h2>Restart-Strategien für Anwendungen</h2><div class="ulist"><ul><li><p>Wenn eine Anwendung abstürzt, versucht Flink diese ggf. neuzustarten</p></li><li><p>um diese Funktionalität zu aktivieren, muss der Parameter <em>restart-strategy.type</em> gesetzt sein (bzw. eine Strategie der Streams API konfiguriert werden)</p></li><li><p>Mögliche Strategien:</p><div class="ulist"><ul><li><p>Fixed Delay: Es wird versucht, die Anwendung in regelmäßigen Abständen neuzustarten, bis zu einer gewissen maximalen Anzahl von Versuchen</p></li><li><p>Failure Rate Restart: Startet die Anwendung neu, sofern eine bestimmte Failure Rate (Anzahl von Crashs in einem gewissen Zeitintervall) nicht überschritten wurde</p></li><li><p>No Restarts (default)</p></li></ul></div></li></ul></div></section>
<section id="_security"><h2>Security</h2><div class="ulist"><ul><li><p>Flink kann alle Netzwerkkommunikation mit SSL verschlüsseln</p><div class="ulist"><ul><li><p>Cluster-Intern verwendet Flink für alle Netzwerkkommunikation gegenseitige SSL-Authentifizierung</p></li></ul></div></li><li><p>Für externe Kommunikation unterstützt Flink auch das Kerberos-Protokoll</p><div class="ulist"><ul><li><p>Dies kann nur für bestimmte Konnektoren verwendet werden (Kafka, HDFS, HBase)</p></li></ul></div></li><li><p>Da alle externe Kommunikation (z.B. Anfragen, Jobs starten) über eine REST-Schnittstelle läuft, kann diese auch mit SSL arbeiten</p></li><li><p>Oder man kann manuell einen Proxy-Service für die Authentifizierung an der Schnittstelle einrichten</p><div class="ulist"><ul><li><p>Im managed Cluster kann dieser die Aufgabe übernehmen</p></li></ul></div></li></ul></div></section>
<section id="_state_backend_konfiguration"><h2>State Backend Konfiguration</h2><div class="ulist"><ul><li><p>wichtigste Parameter sind</p><div class="ulist"><ul><li><p><em>state.backend.type</em> (out-of-the-box möglich: hashmap, rocksdb)</p></li><li><p><em>state.checkpoint-storage</em> (jobmanager oder filesystem),</p></li><li><p><em>state.backend.local-recovery</em> : wenn true (default: false), wird der State eines Operators zusätzlich im lokalen Dateisystem der Node gespeichert</p><div class="ulist"><ul><li><p>Bei Recovery wird zunächst das lokale Dateisystem abgefragt, dann das externe Backend</p></li><li><p>Kann Recovery beschleunigen, aber verlangsamt den Betrieb, wenn keine Fehler auftreten</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_speicherkonfiguration"><h2>Speicherkonfiguration</h2><div class="ulist"><ul><li><p>Ein eher technisches Betriebsthema, das nicht Teil dieser Einführung ist, aber Details können in der Flink-Dokumentation gefunden werden, z.B.:</p><div class="ulist"><ul><li><p><a href="https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/memory/mem_setup_tm/" class="bare">https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/memory/mem_setup_tm/</a></p></li><li><p><a href="https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/memory/network_mem_tuning/" class="bare">https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/memory/network_mem_tuning/</a></p></li></ul></div></li></ul></div></section>
<section id="_slot_sharing_groups"><h2>Slot Sharing Groups</h2><div class="ulist"><ul><li><p>per Default wird bei der Ausführung eines Jobs jeder Slice genau einem Task Slot eines TaskManagers zugeordnet</p></li><li><p>Durch Festlegen von Task Groups (synonym: Slot Sharing Groups) kann ein Slice bzw. eine Pipeline in mehrere Abschnitte unterteilt werden, die dann jeweils einen
eigenen Task Slot belegen</p><div class="ulist"><ul><li><p>Dies kann bei komplexen Pipelines Sinn ergeben, wenn die Resourcen eines Task Slots zu beschränkt sind</p><div class="ulist"><ul><li><p>Alternativ kann auch die Anzahl der Task Slots pro Task Manager oder die Anzahl der Task Manager auf einer Node, oder die zugewiesenen Resourcen für einen TaskManager, oder
der Paralellismus des Jobs manipuliert werden&#8230;&#8203;</p></li></ul></div></li></ul></div></li><li><p>Um die Task Group für einen Operator in der Fluent API festzulegen, kann nach Anwendung des Operators die Methode slotSharingGroup(&lt;group_name&gt;) ausgeführt werden</p><div class="ulist"><ul><li><p>Downstream Operatoren erben dann diese Gruppe</p></li></ul></div></li></ul></div></section>
<section id="_einstellungen_für_checkpoints"><h2>Einstellungen für Checkpoints</h2><div class="ulist"><ul><li><p>Es ist zu empfehlen, Checkpointing zu aktivieren (ist per Default nicht aktiv)</p></li><li><p>Hierfür kann der Konfigurationsparameter <em>execution.checkpointing.interval</em> auf einen Wert größer 0 gesetzt werden, oder die Methode enableCheckpointing(interval) auf dem ExecutionEnvironment
ausgeführt werden</p></li><li><p>Weitere mögliche Konfigurationen (jeweils mit Parametern oder Java API möglich):</p><div class="ulist"><ul><li><p>Checkpointing Mode : Exactly Once (default) oder At least Once</p></li><li><p>minimum time between checkpoints : Mindestwartezeit zwischen Abschluss eines Checkpoints und Beginn des nächsten (muss kleiner als Checkpoint Interval sein)</p></li><li><p>tolerable checkpoint failure number : Wenn mehr als diese Anzahl von Malen hintereinander ein Checkpoint fehlschlägt, breche Job ab</p><div class="ulist"><ul><li><p>default ist 0 : Breche bei jedem Checkpoint failure ab</p></li><li><p>nur bestimmte Arten von failures können toleriert werden (siehe <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/fault-tolerance/checkpointing/" class="bare">https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/fault-tolerance/checkpointing/</a> )</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_einstellungen_für_checkpoints_2"><h2>Einstellungen für Checkpoints (2)</h2><div class="ulist"><ul><li><p>number of concurrent checkpoints : Anzahl von Checkpoints, die parallel durchgeführt werden dürfen (default : 1)</p></li><li><p>unaligned checkpoints : wenn true, benutze unaligned checkpointing (inkompatibel mit concurrent checkpoints)</p></li><li><p>externalized checkpoints : steuert ob Checkpoints zusätzlich im externen Speicher persistiert werden (default : nein)</p><div class="ulist"><ul><li><p>Checkpoint Storage-Typ kann mit <em>state.checkpoint-storage</em> kontrolliert werden</p></li><li><p>Job kann dann auch nach cancel manuell vom letzten Checkpoint geladen werden</p></li><li><p>ersetzt nicht Savepoints, da weniger flexibel</p></li></ul></div></li><li><p>Checkpoint Compression kann mit executionConfig.setUseSnapshotCompression(true) aktiviert werden (ExecutionConfig aus Environment mit env.getConfig())</p></li></ul></div></section>
<section id="_savepoints_konsolenbefehle"><h2>Savepoints : Konsolenbefehle</h2><div class="ulist"><ul><li><p>Kommandozeilenbefehle für Savepoints:</p><div class="ulist"><ul><li><p>./bin/flink savepoint [--type [native/canonical]] &lt;jobId&gt; [savepointPath]</p><div class="ulist"><ul><li><p>erstellt für den Job mit der angegebenen ID einen Savepoint am angegebenen Ordner (wenn leer, nehme als Default den Wert des Parameters <em>savepoints.dir</em>)</p></li><li><p>Default type ist canonical (s.u.)</p></li><li><p>nach Abschluss des Savepoints wird auf der Konsole ein Pfad zu der entsprechenden Datei ausgebenen</p></li></ul></div></li><li><p>./bin/flink savepoint -d &lt;savepointPath&gt;</p><div class="ulist"><ul><li><p>löscht Savepoint mit dem angegebenen Pfad</p></li></ul></div></li><li><p>./bin/flink run -s &lt;savepointPath&gt; [options] &lt;jobJar&gt; [arguments]</p><div class="ulist"><ul><li><p>Startet Job vom angegebenen Savepoint mit ggf. weiteren Optionen und Kommandozeilenargumenten für die Anwendung</p></li></ul></div></li><li><p>./bin/flink stop --type [native/canonical] --savepointPath [savepointPath] &lt;jobId&gt;</p><div class="ulist"><ul><li><p>erstellt Savepoint und stoppt Job direkt danach</p></li></ul></div></li></ul></div></li></ul></div></section>
<section id="_savepoints_einschränkungen_und_tipps"><h2>Savepoints : Einschränkungen und Tipps</h2><div class="ulist"><ul><li><p>Wichtig : Für das Funktionieren von sowohl Checkpoints als auch Savepoints sollten alle stateful Operatoren einen ID haben, damit die State-Informationen zugeordnet werden können</p><div class="ulist"><ul><li><p>eine ID kann in der API mit der Methode .uid(&lt;id_string&gt;) hinzugefügt werden</p></li><li><p>andernfalls werden Operatoren über ihre Position im JobGraph identifiziert (nicht robust bei Veränderungen)</p></li></ul></div></li><li><p>eine aufschlussreiche Übersicht, welche Arten von Veränderungen im Job von (aligned/unaligned) Checkpoints bzw. Savepoints toleriert werden können, findet sich hier:
<a href="https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/checkpoints_vs_savepoints/" class="bare">https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/checkpoints_vs_savepoints/</a></p><div class="ulist"><ul><li><p>kanonische Savepoints (default) verwenden eine generetische Formatierung, die nicht vom State Backend abhängt, und ermöglichen den Wechsel des State Backend Typs</p></li><li><p>native Savepoints sind an eine spezielle Art von Backend gebunden und können schneller sein</p></li></ul></div></li></ul></div></section>
<section id="_savepoints_einschränkungen_und_tipps_2"><h2>Savepoints : Einschränkungen und Tipps (2)</h2><div class="ulist"><ul><li><p>Es gibt leichte Einschränkungen, wie Operator State geändert werden darf, sodass die Anwendung noch kompatibel mit einem Savepoint ist:</p><div class="ulist"><ul><li><p>Bei Hinzufügen von State gibt es keine Probleme (Zustand wird als leer initialisiert)</p></li><li><p>Bei Entfernen von State wird die Anwendung per Default nicht gestartet, da es Inkompatibilitäten geben könnte</p><div class="ulist"><ul><li><p>Dieses Verhalten kann mit der Option "-n" übergangen werden</p></li></ul></div></li><li><p>Schema Evolution : Bei Veränderung des Datentyps eines States kann es sein, dass die Anwendung inkompatibel mit dem Savepoint wird</p><div class="ulist"><ul><li><p>wenn der Serialisierer des Statetyps Schema Evolution unterstützt (z.B. POJO- oder Avro-Typen), wird aber Kompatibilität garantiert</p></li></ul></div></li></ul></div></li><li><p>Um Exactly-Once bei Updates oder Rescaling zu garantieren, sollten Savepoints über den stop-Befehl erstellt werden (s.o.)</p><div class="ulist"><ul><li><p>Sonst könnten Daten, die zwischen Erstellung des Savepoints und Stop des Jobs eintreffen, zweimal bearbeitet werden</p></li></ul></div></li></ul></div></section>
<section id="_monitoring"><h2>Monitoring</h2><div class="ulist"><ul><li><p>Es gibt einige eingebaute Metriken, die von Flink automatisch erhoben werden, z.B. :</p></li><li><p>JobManager/TaskManager Scope:</p><div class="ulist"><ul><li><p>Speicherbenutzung von TaskManagern und JobManager</p></li></ul></div></li><li><p>Job Scope:</p><div class="ulist"><ul><li><p>Anzahl der Restarts eines Jobs (pro Zeit)</p></li><li><p>Anzahl der (erfolgreichen/nicht erfolgreichen) Checkpoints</p></li></ul></div></li><li><p>Operator Scope:</p><div class="ulist"><ul><li><p>Anzahl der gesendeten/empfangenen Datensätze pro Sekunde (Throughput)</p></li><li><p>aktuelle Watermark</p></li><li><p>Latenz von Quellenoperatoren zu diesem Operator</p><div class="ulist"><ul><li><p>ist nicht per Default aktiviert (Latency Tracking)</p></li><li><p>wird durch Hinzufügen spezieller Datensätze an der Quelle approximativ berechnet</p></li></ul></div></li></ul></div></li><li><p>&#8230;&#8203; u.v.m.</p></li></ul></div></section>
<section id="_monitoring_2"><h2>Monitoring (2)</h2><div class="ulist"><ul><li><p>In der Flink Web UI können sämtliche Metriken eingesehen werden (eigene Metriken ggf. mit "Add Metric" in der Jobanzeige hinzufügen)</p></li><li><p>Eigene Metriken können in der Java API über das MetricGroup Interface registriert werden</p><div class="ulist"><ul><li><p>Man erhält eine MetricGroup über die getMetricGroup()-Methode innerhalb einer Operatorfunktion auf einem RuntimeContext (erfordert RichFunction)</p></li></ul></div></li><li><p>Es können die folgenden Typen von Metriken definiert werden:</p><div class="ulist"><ul><li><p>Counter : können einen Zahlenwert inkrementieren oder dekrementieren</p></li><li><p>Gauge : können den Wert einer einzelnen Variable (beliebigen Typs) aktualisieren</p></li><li><p>Meter : zählt die Anzahl von Ereignissen pro Sekunde</p></li><li><p>Histogram : misst die Verteilung von Werten</p></li></ul></div></li><li><p>Man kann innerhalb der RichFunction eine <em>transient</em> Variable deklarieren, die den Wert der Metrik enthält</p></li></ul></div></section>
<section id="_monitoring_3"><h2>Monitoring (3)</h2><div class="ulist"><ul><li><p>Codebeispiel Counter:</p></li></ul></div>
<pre class="CodeRay listingblock"><code class="java language-java"><span class="directive">public</span> <span class="type">class</span> <span class="class">MyMapper</span> <span class="directive">extends</span> RichMapFunction&lt;<span class="predefined-type">String</span>, <span class="predefined-type">String</span>&gt; {
  <span class="directive">private</span> <span class="directive">transient</span> Counter counter;

  <span class="annotation">@Override</span>
  <span class="directive">public</span> <span class="type">void</span> open(<span class="predefined-type">Configuration</span> config) {
    <span class="local-variable">this</span>.counter = getRuntimeContext()
      .getMetricGroup()
      .counter(<span class="string"><span class="delimiter">&quot;</span><span class="content">myCustomCounter</span><span class="delimiter">&quot;</span></span>, <span class="keyword">new</span> CustomCounter());
  }

  <span class="annotation">@Override</span>
  <span class="directive">public</span> <span class="predefined-type">String</span> map(<span class="predefined-type">String</span> value) <span class="directive">throws</span> <span class="exception">Exception</span> {
    <span class="local-variable">this</span>.counter.inc();
    <span class="keyword">return</span> value;
  }
}</code></pre>
<div class="paragraph"><p>Codequelle: <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/ops/metrics/" class="bare">https://nightlies.apache.org/flink/flink-docs-master/docs/ops/metrics/</a></p></div></section>
<section id="_monitoring_4"><h2>Monitoring (4)</h2><div class="ulist"><ul><li><p>Jede Metric hat einen Scope, der sich aus einem User Scope und einem System Scope zusammensetzt, wobei der User Scope in der Anwendung konfigurierbar ist</p><div class="ulist"><ul><li><p>bei Ausführung von addGroup(&lt;name&gt;) auf einer vorhandenen MetricGroup wird eine neue Metric Group mit geschachteltem Scope erstellt</p></li></ul></div></li><li><p>System Scope enthält z.B. Informationen über den Job und Task, zu denen die Metrik gehört</p></li><li><p>Scope zusammen mit dem Namen der Metric identifizieren diese eindeutig</p></li><li><p>Um die Metriken extern verfügbar zu machen, müssen sog. Reporter verwendet werden</p><div class="ulist"><ul><li><p>Es gibt einige vordefinierte Implementierungen wie z.B. PrometheusReporter, Slf4jReporter, JMXReporter</p></li></ul></div></li><li><p>Die verwendeten Reporter müssen in <em>flink-conf.yaml</em> (implementierungsabhängig) konfiguriert werden</p><div class="ulist"><ul><li><p>Für Details siehe <a href="https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/metric_reporters/" class="bare">https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/metric_reporters/</a></p></li></ul></div></li></ul></div></section>
<section id="_aufgabe_9_checkpoints_und_recovery"><h2>Aufgabe 9 : Checkpoints und Recovery</h2><div class="ulist"><ul><li><p>Wir lassen in dieser Aufgabe einen Job mit verschiedenen Checkpointing-Strategien laufen und beobachten die automatische Recovery-Funktion von Flink</p><div class="olist arabic"><ol class="arabic"><li><p>Für die Aufgabe ist in den Unterlagen eine docker-compose.yml zu finden, die Sie mit "docker compose up --build -d" starten können</p><div class="ulist"><ul><li><p>Dies startet ein Docker-Netzwerk mit einem Jobmanager und 2 Taskmanagern auf verschiedenen Containern</p></li></ul></div></li><li><p>Führen Sie in einem Konsolenfenster "docker compose logs -f" aus und beobachten Sie im Folgenden die Logausgaben</p></li><li><p>Es ist ein kleiner Job vorbereitet, den Sie starten können, indem Sie z.B. auf den Jobmanager mit "docker exec -it aufgabe-09-jobmanager-1 /bin/bash" wechseln und dann
dort "./bin/flink run counting-job.jar" ausführen</p></li></ol></div></li><li><p>Der Job erhöht einmal pro Sekunde einen Zähler und schreibt die Zahl in eine Datei</p><div class="ulist"><ul><li><p>Die Datei ist auf einen Ordner Ihres lokales Dateisystem gemounted (/aufgabe9-joblog)</p></li></ul></div></li><li><p>Es gibt aber das Problem, dass der No-Op-Operator, der mit Parallelismus 2 arbeitet, für die Verarbeitung von geraden Zahlen deutlich länger braucht als für die ungeraden Zahlen</p></li></ul></div></section>
<section id="_aufgabe_9_checkpoints_und_recovery_2"><h2>Aufgabe 9 : Checkpoints und Recovery (2)</h2><div class="olist arabic"><ol class="arabic" start="4"><li><p>Sehen Sie im Log nach, dass in regelmäßigen Abständen Checkpoints erstellt werden und wie viel Zeit dafür benötigt wird</p></li><li><p>Stellen Sie fest, welcher der beiden TaskManager den Job bearbeitet</p></li><li><p>Simulieren Sie einen unerwarteten Ausfall, indem Sie in diesem Taskmanager (z.B. erst "docker exec -it aufgabe-09-taskmanager-1 /bin/bash") den Konsolenbefehl "kill 1" ausführen (beendet Hauptprozess)</p></li><li><p>Überprüfen Sie durch Betrachten der Logs und der Ausgabe des Jobs in der angelegten Datei, ob der andere TaskManager den Job übernommen hat, und nach Laden eines Checkpoints die Konsistenzgarantie
"exactly once" eingehalten wurde</p><div class="ulist"><ul><li><p>Der Job counting-job.jar kann auch mit den Parametern "at-least-once-checkpointing" oder "exactly-once-checkpointing unaligned" ausgeführt werden</p></li></ul></div></li><li><p>Wiederholen Sie in beiden Fällen die gleichen Schritte wie im ersten Fall und vergleichen Sie die Ergebnisse</p></li><li><p>Testen Sie auch noch, manuell einen Savepoint des Jobs zu erstellen und wieder zu laden</p></li></ol></div></section></div></div><script src="reveal.js-3.9.2/lib/js/head.min.js"></script><script src="reveal.js-3.9.2/js/reveal.js"></script><script>// See https://github.com/hakimel/reveal.js#configuration for a full list of configuration options
Reveal.initialize({
  // Display controls in the bottom right corner
  controls: true,
  // Display a presentation progress bar
  progress: true,
  // Display the page number of the current slide
  slideNumber: true,
  // Push each slide change to the browser history
  history: true,
  // Enable keyboard shortcuts for navigation
  keyboard: true,
  // Enable the slide overview mode
  overview: true,
  // Vertical centering of slides
  center: true,
  // Enables touch navigation on devices with touch input
  touch: true,
  // Loop the presentation
  loop: false,
  // Change the presentation direction to be RTL
  rtl: false,
  // Turns fragments on and off globally
  fragments: true,
  // Flags if the presentation is running in an embedded mode,
  // i.e. contained within a limited portion of the screen
  embedded: false,
  // Number of milliseconds between automatically proceeding to the
  // next slide, disabled when set to 0, this value can be overwritten
  // by using a data-autoslide attribute on your slides
  autoSlide: 0,
  // Stop auto-sliding after user input
  autoSlideStoppable: true,
  // Enable slide navigation via mouse wheel
  mouseWheel: true,
  // Hides the address bar on mobile devices
  hideAddressBar: true,
  // Opens links in an iframe preview overlay
  previewLinks: false,
  // Theme (e.g., beige, black, league, night, serif, simple, sky, solarized, white)
  // NOTE setting the theme in the config no longer works in reveal.js 3.x
  //theme: Reveal.getQueryHash().theme || 'anderscore',
  // Transition style (e.g., none, fade, slide, convex, concave, zoom)
  transition: Reveal.getQueryHash().transition || 'linear',
  // Transition speed (e.g., default, fast, slow)
  transitionSpeed: 'default',
  // Transition style for full page slide backgrounds (e.g., none, fade, slide, convex, concave, zoom)
  backgroundTransition: 'fade',
  // Number of slides away from the current that are visible
  viewDistance: 3,
  // Parallax background image (e.g., "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'")
  parallaxBackgroundImage: '',
  // Parallax background size in CSS syntax (e.g., "2100px 900px")
  parallaxBackgroundSize: '',

  // The "normal" size of the presentation, aspect ratio will be preserved
  // when the presentation is scaled to fit different resolutions. Can be
  // specified using percentage units.
  width: 1728,
  height: 972,

  // Factor of the display size that should remain empty around the content
  margin: 0.1,

  // Bounds for smallest/largest possible scale to apply to content
  minScale: 0.2,
  maxScale: 1.5,

  // Optional libraries used to extend on reveal.js
  dependencies: [
      { src: 'reveal.js-3.9.2/lib/js/classList.js', condition: function() { return !document.body.classList; } },
      { src: 'reveal.js-3.9.2/plugin/title-footer/title-footer.js', async: true, callback: function()
          {title_footer.initialize('Schulung Java Data Pipelines mit Apache Flink', 'Jan Lühr', 'anderScore GmbH • Frankenwerft 35 • 50667 Köln');}},
      { src: 'reveal.js-3.9.2/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'reveal.js-3.9.2/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      
      { src: 'reveal.js-3.9.2/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
      { src: 'reveal.js-3.9.2/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
  ]
});</script></body></html>